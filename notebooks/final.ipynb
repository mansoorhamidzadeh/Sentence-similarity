{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59634ce9c3b65d9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T13:15:58.669386151Z",
     "start_time": "2024-02-06T13:15:53.870584003Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import torch\n",
    "from farsi_tools import stop_words\n",
    "from hazm import word_tokenize, Lemmatizer\n",
    "from pymongo import MongoClient\n",
    "from sentence_transformers import util\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from tqdm import tqdm\n",
    "from values.Values import *\n",
    "import constance"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "word2vec_cbow_path = '../dataset/word2vec.model-cbow-size=200-window=5.bin'\n",
    "\n",
    "lemmatizer = Lemmatizer()"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:08:07.006486864Z",
     "start_time": "2024-02-06T11:08:06.704444833Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# STOP WORD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7c77a87b83e36c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(stopword_path, encoding=\"utf8\") as f:\n",
    "    stop = f.readlines()\n",
    "# cleaning stopwords\n",
    "stop_word = [word.replace('\\n', '') for word in stop]\n",
    "stop_word = [re.sub('[\\\\u200c]', ' ', word) for word in stop_word]\n",
    "stop_word.extend(stop_words())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:08:10.657906861Z",
     "start_time": "2024-02-06T11:08:10.528337107Z"
    }
   },
   "id": "809d5e464de0f548",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# mongo db"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a02083f5fd62333"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def context_mongo(collection_name):\n",
    "    client = MongoClient(host=host, port=port)\n",
    "    client_my = client['nlp']\n",
    "    my_coll = client_my[collection_name]\n",
    "    return my_coll"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:08:16.702221625Z",
     "start_time": "2024-02-06T11:08:16.569058890Z"
    }
   },
   "id": "af4243d203e0764",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# glove"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c244294e25495c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file):\n",
    "    print(\"loading glove model\")\n",
    "    model = KeyedVectors.load_word2vec_format(glove_file, binary=False)\n",
    "    print(f\"loaded glove model , {len(model)}\")\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:08:27.409088046Z",
     "start_time": "2024-02-06T11:08:27.282878100Z"
    }
   },
   "id": "158789c508936a54",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading glove model\n",
      "loaded glove model , 240548\n"
     ]
    }
   ],
   "source": [
    "model = load_glove_model(glove_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:08:41.390627804Z",
     "start_time": "2024-02-06T11:08:28.106127065Z"
    }
   },
   "id": "585a8ae0ed3a0c63",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# spell checker"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dabb2dbbca5ad531"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=3, prefix_length=8)\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:08:47.950081126Z",
     "start_time": "2024-02-06T11:08:41.389227112Z"
    }
   },
   "id": "945388cf874c129c",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# word 2 vector sy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f63a1016287ab41"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "word2vec_model = KeyedVectors.load_word2vec_format(word2vec_cbow_path, binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:08:51.994486157Z",
     "start_time": "2024-02-06T11:08:47.927564378Z"
    }
   },
   "id": "645fa766192b1d21",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test = \"تعیین مقادیر پیش فرض در ماژول جلسات\"\n",
    "test1 = \"تعیین مقادیر پیش فرض در افزونه جلسات\"\n",
    "text = \"ویدئو انیمیشن برای همکارات بفرست\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:08:52.030545402Z",
     "start_time": "2024-02-06T11:08:51.996666011Z"
    }
   },
   "id": "8a6efae14b0e9174",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[('ERP', 0.8689835071563721),\n ('اتوماسیون', 0.8578999042510986),\n ('راهبری', 0.8481571674346924),\n ('ICT', 0.8443616628646851),\n ('کسب\\u200cوکار', 0.8366156220436096),\n ('زیرساختی', 0.8302525877952576),\n ('Management', 0.8295701146125793),\n ('SAP', 0.8287033438682556),\n ('خودکارسازی', 0.827669084072113),\n ('مدیریتی', 0.824644923210144)]"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.most_similar_cosmul('IT')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:54:19.089172730Z",
     "start_time": "2024-02-06T11:54:18.899858349Z"
    }
   },
   "id": "ed453e5641f7572d",
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "518d70a70faf0c24"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def read_dataset_csv(csv_fine_path):\n",
    "    df = pd.read_csv(csv_fine_path)  # read csv file\n",
    "    data_list = df.to_dict(orient='records')  # reshape to dict\n",
    "    return data_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:10:07.564151450Z",
     "start_time": "2024-02-06T11:10:07.459894037Z"
    }
   },
   "id": "62644542e6b7988c",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def encode_to_db(collection_name):\n",
    "    collection_name = MongoClient(host, port)\n",
    "    client = collection_name['nlp']\n",
    "    my_collection = client['encoded_new_coll_collection']\n",
    "    main_collection = client['new_coll']\n",
    "    dict_list = [i['job'] for i in main_collection.find({}, {'job'})]\n",
    "    for i in tqdm(dict_list):\n",
    "        if my_collection.find_one({'text': i}):\n",
    "            pass\n",
    "        else:\n",
    "            my_collection.insert_one({\n",
    "                'text': i,\n",
    "                'encoded': word_embedding_method(i)\n",
    "            })\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:10:07.911806735Z",
     "start_time": "2024-02-06T11:10:07.790490308Z"
    }
   },
   "id": "3ff0af5e2a555829",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#encode_to_db('nlp')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:10:08.737311241Z",
     "start_time": "2024-02-06T11:10:08.654677275Z"
    }
   },
   "id": "d71d5d5dc2afe7de",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def word_embedding_method(sentence):\n",
    "    try:\n",
    "        encoded_word_list = []\n",
    "        for i in preprocess(sentence):\n",
    "            if i in model:\n",
    "                encoded_word_list.append(model[i])\n",
    "            else:\n",
    "                continue\n",
    "        if encoded_word_list is None:\n",
    "            return None\n",
    "        else:\n",
    "            return np.mean(encoded_word_list, axis=0).tolist()\n",
    "    except KeyError as e:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:10:09.595657779Z",
     "start_time": "2024-02-06T11:10:09.497733479Z"
    }
   },
   "id": "541ff8adaf1bb8ce",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:10:10.384687803Z",
     "start_time": "2024-02-06T11:10:10.295534729Z"
    }
   },
   "id": "130b302f65edf91e",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "# preprocess"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad6c4c7ed8a3ff76"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(raw_text):\n",
    "    words = word_tokenize(raw_text)  # split a sentence to words and return an array\n",
    "    words = [i for i in words if i not in stop_word]\n",
    "    spell_checker_list = []\n",
    "    for i in range(len(words)):  # iterate in word array for checking spell\n",
    "        if not sym_spell.lookup(words[i], Verbosity.ALL, max_edit_distance=3):  # if word not exists ignore the word\n",
    "            continue\n",
    "        else:\n",
    "            word_matched = sym_spell.lookup(words[i], Verbosity.ALL, max_edit_distance=3)\n",
    "            for i in word_matched[:1]:  # take first similar word to our incorrect word\n",
    "                spell_checker_list.append(i)\n",
    "    #lemmatize = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    split_lemm_words = []\n",
    "    for i in words:\n",
    "\n",
    "        if \"#\" not in i:\n",
    "            split_lemm_words.append(i)\n",
    "        else:\n",
    "            split_lemm_words.extend(i.split(\"#\"))\n",
    "    clean_words = list(set([w for w in split_lemm_words if w not in stop_word]))  # remove some word like \"و ,با, ...\"\n",
    "\n",
    "    return clean_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:10:11.386845874Z",
     "start_time": "2024-02-06T11:10:11.287652547Z"
    }
   },
   "id": "7d3d8d7aab206f49",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# word synonyms "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c1343f6cadbc8a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_similarity_of_words(sentence1, sentence2):\n",
    "    sentence_1 = preprocess(sentence1)\n",
    "\n",
    "    sentence_word_similarity = {}\n",
    "    for i in sentence_1:\n",
    "        get_similarity = word2vec_model.most_similar_cosmul(i, topn=20)\n",
    "        lemm = [lemmatizer.lemmatize(word[0]) for word in get_similarity]\n",
    "        cleaning_words = [re.sub(r'[\\u200c]', '', word) for word in lemm]\n",
    "        sentence_word_similarity[i] = list(set(cleaning_words))\n",
    "    gf_list = {}\n",
    "    for sent in sentence2:\n",
    "        sentence_2 = preprocess(sent)\n",
    "        reformed_sentence = sentence_2.copy()\n",
    "        for i, j in sentence_word_similarity.items():\n",
    "            for x in sentence_2:\n",
    "                if x in j:\n",
    "                    reformed_sentence = [i if word == x else word for word in reformed_sentence]\n",
    "        gf_list = {**gf_list, **{sent: ' '.join(reformed_sentence)}}\n",
    "    return gf_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:10:12.422904612Z",
     "start_time": "2024-02-06T11:10:12.319338697Z"
    }
   },
   "id": "89d158463b8de6c1",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# *Similarity*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47a28b6ae373519f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def final_similarity(sentence):\n",
    "    my_collection = context_mongo('new_version_of_cleaned_dataset')\n",
    "\n",
    "    vector_1 = np.mean([word_embedding_method(sentence)], axis=0)\n",
    "    result_pass = [calculate_similarity_of_words(sentence, [i['cleaned_text'] for i in my_collection.find()][:50])]\n",
    "\n",
    "    op = {}\n",
    "    for i in result_pass:\n",
    "        for j in i.values():\n",
    "            if len(j.split(' ')) > 1:\n",
    "                op[j] = np.mean([word_embedding_method(j)], axis=0)\n",
    "            else:\n",
    "                if type(word_embedding_method(j)) == float:\n",
    "                    continue\n",
    "                else:\n",
    "                    op[j] = word_embedding_method(j)\n",
    "    result_dict = {}\n",
    "    result = util.cos_sim(vector_1, np.array([j if i else None for i, j in op.items()], dtype=float))[0]\n",
    "    top_results = torch.topk(result, k=5)\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        result_dict[list(result_pass[0].keys())[int(idx)]] = np.round(score.numpy() * 100, 2)\n",
    "    return result_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:10:32.896082632Z",
     "start_time": "2024-02-06T11:10:32.782791809Z"
    }
   },
   "id": "8070a66963c2c8a7",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'محتوای ایمیل مارکتینگ روز چهاردهم': 100.0,\n 'برنامه تکمیلی واحد بازاریابی سال': 89.79,\n 'راهنمای مدیریت پروژه': 89.45,\n 'محتوای صفحات وب مدیریت پروژه': 86.31,\n 'طراحی سایت همسو و صفحات داخلی آن': 85.22}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_similarity(\"محتوای صفحه هدف و قیمت گذاری ثبت نام\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:10:56.336605197Z",
     "start_time": "2024-02-06T11:10:33.451251320Z"
    }
   },
   "id": "18a6a3de720dc50c",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# Sent By Sent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0c32c70702b9b77"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_similarity_of_words(sentence1, sentence2):\n",
    "    sentence_1 = preprocess(sentence1)\n",
    "    sentence_word_similarity = {}\n",
    "    for i in sentence_1:\n",
    "        get_similarity = word2vec_model.most_similar_cosmul(i, topn=20)\n",
    "        lemm = [lemmatizer.lemmatize(word[0]) for word in get_similarity]\n",
    "        cleaning_words = [re.sub(r'[\\u200c]', '', word) for word in lemm]\n",
    "        sentence_word_similarity[i] = list(set(cleaning_words))\n",
    "\n",
    "    sentence_2 = preprocess(sentence2)\n",
    "\n",
    "    reformed_sentence = sentence_2.copy()\n",
    "    for i, j in sentence_word_similarity.items():\n",
    "        for x in sentence_2:\n",
    "            if x in j:\n",
    "                reformed_sentence = [i if word == x else word for word in reformed_sentence]\n",
    "    gf_list = ' '.join(reformed_sentence)\n",
    "    return gf_list\n",
    "\n",
    "\n",
    "def single_sim(sentence1, sentence2):\n",
    "    vector_1 = np.mean([word_embedding_method(sentence1)], axis=0)\n",
    "    result_pass = calculate_similarity_of_words(sentence1, sentence2)\n",
    "\n",
    "    op = {}\n",
    "    if len(result_pass.split(' ')) > 1:\n",
    "        op[result_pass] = np.mean([word_embedding_method(result_pass)], axis=0)\n",
    "    else:\n",
    "        if type(word_embedding_method(result_pass)) == float:\n",
    "            pass\n",
    "        else:\n",
    "            op[result_pass] = word_embedding_method(result_pass)\n",
    "    result_dict = {}\n",
    "    result = util.cos_sim(vector_1, np.array([j if i else None for i, j in op.items()], dtype=float))[0]\n",
    "    return result\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:13:48.979236632Z",
     "start_time": "2024-02-06T11:13:48.867090944Z"
    }
   },
   "id": "d1299fb83cea30b3",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.9442], dtype=torch.float64)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"تولید پرسونا برای برنامه ریزی سخنرانی\"\n",
    "text1 = \"تهیه پرسونا برای مدیریت جلسات\"\n",
    "single_sim(text, text1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:13:51.009776894Z",
     "start_time": "2024-02-06T11:13:50.192063602Z"
    }
   },
   "id": "c321ae545e284b37",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "# for faster calculation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6778dc354076d669"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "my_collection = context_mongo('new_version_of_cleaned_dataset')\n",
    "sentences = [i['cleaned_text'] for i in my_collection.find()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:13:56.499823358Z",
     "start_time": "2024-02-06T11:13:56.347310474Z"
    }
   },
   "id": "d72e2db756fd46ab",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_upload(sentences):\n",
    "    all_predicted_sentences = {}\n",
    "    for i in tqdm(sentences):\n",
    "        tokenized = preprocess(i)\n",
    "        if len(tokenized) > 0:\n",
    "            ref_with_sim = {}\n",
    "            for word in tokenized:\n",
    "                sim_words_array = []\n",
    "                try:\n",
    "                    get_similarity = word2vec_model.most_similar_cosmul(word, topn=10)\n",
    "                    for similarity in get_similarity:\n",
    "                        sim_words_array.append(similarity[0])\n",
    "                except:\n",
    "                    pass\n",
    "                ref_with_sim = {**ref_with_sim, **{word: sim_words_array}}\n",
    "            maked_sentence = []\n",
    "            for tokenized_word in preprocess(i):\n",
    "                for l, m in ref_with_sim.items():\n",
    "                    if l == tokenized_word:\n",
    "                        for ih in m:\n",
    "                            maked_sentence.append(str(i).replace(l, ih))\n",
    "            all_predicted_sentences = {**all_predicted_sentences, **{i: maked_sentence}}\n",
    "        else:\n",
    "            continue\n",
    "    return all_predicted_sentences\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:15:01.132297318Z",
     "start_time": "2024-02-06T11:15:01.044842928Z"
    }
   },
   "id": "d32a7abeabe2ac00",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_syn = context_mongo('all_syn')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:21:30.362747441Z",
     "start_time": "2024-02-06T11:21:30.265257649Z"
    }
   },
   "id": "7df6cd8fd41ddd28",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, j in find_upload(sentences[:10]).items():\n",
    "    if all_syn.find_one({'name': i}):\n",
    "        pass\n",
    "    else:\n",
    "        all_syn.insert_one({\n",
    "            \"name\": i,\n",
    "            \"encoded\": j\n",
    "        })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:19:02.074319014Z",
     "start_time": "2024-02-06T11:18:56.132710034Z"
    }
   },
   "id": "52eb078cf5313381",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "syn_encoded = context_mongo('syn_encoded')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:21:11.306348991Z",
     "start_time": "2024-02-06T11:21:11.209592092Z"
    }
   },
   "id": "224d964aebc3898a",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6513it [00:48, 134.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m syn_encoded_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m i[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoded\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m----> 7\u001B[0m     syn_encoded_list\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39mmean([\u001B[43mword_embedding_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m)\u001B[49m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mtolist())\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m syn_encoded_list:\n\u001B[1;32m      9\u001B[0m     syn_encoded\u001B[38;5;241m.\u001B[39minsert_one({\n\u001B[1;32m     10\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m: i[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     11\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenerated_sent\u001B[39m\u001B[38;5;124m'\u001B[39m: i[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoded\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_encoded\u001B[39m\u001B[38;5;124m'\u001B[39m: syn_encoded_list\n\u001B[1;32m     13\u001B[0m \n\u001B[1;32m     14\u001B[0m     })\n",
      "Cell \u001B[0;32mIn[18], line 4\u001B[0m, in \u001B[0;36mword_embedding_method\u001B[0;34m(sentence)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m      3\u001B[0m     encoded_word_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m model:\n\u001B[1;32m      6\u001B[0m             encoded_word_list\u001B[38;5;241m.\u001B[39mappend(model[i])\n",
      "Cell \u001B[0;32mIn[19], line 6\u001B[0m, in \u001B[0;36mpreprocess\u001B[0;34m(raw_text)\u001B[0m\n\u001B[1;32m      4\u001B[0m spell_checker_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(words)):  \u001B[38;5;66;03m# iterate in word array for checking spell\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43msym_spell\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlookup\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwords\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mVerbosity\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mALL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_edit_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m:  \u001B[38;5;66;03m# if word not exists ignore the word\u001B[39;00m\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/sim_sent/lib/python3.10/site-packages/symspellpy/symspellpy.py:616\u001B[0m, in \u001B[0;36mSymSpell.lookup\u001B[0;34m(self, phrase, verbosity, max_edit_distance, include_unknown, ignore_token, transfer_casing)\u001B[0m\n\u001B[1;32m    614\u001B[0m                 candidates\u001B[38;5;241m.\u001B[39mappend(delete)\n\u001B[1;32m    615\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(suggestions) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 616\u001B[0m     \u001B[43msuggestions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transfer_casing:\n\u001B[1;32m    619\u001B[0m     suggestions \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    620\u001B[0m         SuggestItem(\n\u001B[1;32m    621\u001B[0m             helpers\u001B[38;5;241m.\u001B[39mcase_transfer_similar(original_phrase, s\u001B[38;5;241m.\u001B[39mterm),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    625\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m suggestions\n\u001B[1;32m    626\u001B[0m     ]\n",
      "File \u001B[0;32m~/anaconda3/envs/sim_sent/lib/python3.10/site-packages/symspellpy/suggest_item.py:55\u001B[0m, in \u001B[0;36mSuggestItem.__lt__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(other, SuggestItem):\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[0;32m---> 55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distance \u001B[38;5;241m==\u001B[39m \u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistance\u001B[49m:\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_count \u001B[38;5;241m>\u001B[39m other\u001B[38;5;241m.\u001B[39mcount\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distance \u001B[38;5;241m<\u001B[39m other\u001B[38;5;241m.\u001B[39mdistance\n",
      "File \u001B[0;32m~/anaconda3/envs/sim_sent/lib/python3.10/site-packages/symspellpy/suggest_item.py:78\u001B[0m, in \u001B[0;36mSuggestItem.distance\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;129m@count\u001B[39m\u001B[38;5;241m.\u001B[39msetter\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcount\u001B[39m(\u001B[38;5;28mself\u001B[39m, count: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_count \u001B[38;5;241m=\u001B[39m count\n\u001B[0;32m---> 78\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdistance\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[1;32m     80\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Edit distance between searched for word and suggestion.\"\"\"\u001B[39;00m\n\u001B[1;32m     81\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distance\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(all_syn.find({}, {\"_id\": False})):\n",
    "    if syn_encoded.find_one({'text': i['name']}):\n",
    "        pass\n",
    "    else:\n",
    "        syn_encoded_list = []\n",
    "        for m in i['encoded']:\n",
    "            syn_encoded_list.append(np.mean([word_embedding_method(m)], axis=0).tolist())\n",
    "        if syn_encoded_list:\n",
    "            syn_encoded.insert_one({\n",
    "                'text': i['name'],\n",
    "                'generated_sent': i['encoded'],\n",
    "                'mean_encoded': syn_encoded_list\n",
    "\n",
    "            })\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:22:21.550529577Z",
     "start_time": "2024-02-06T11:21:32.924651376Z"
    }
   },
   "id": "af5fdcd3877d08de",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def result(ref):\n",
    "    vector_1 = np.mean([word_embedding_method(ref)], axis=0)\n",
    "    res = {}\n",
    "    for i in tqdm(syn_encoded.find({}, {\"_id\": False})):\n",
    "        result = util.cos_sim(vector_1.tolist(), [ c for c in i['mean_encoded'] if type(c) !=float ])\n",
    "        res[i['text']]=np.mean(sorted(result[0].detach().numpy(),reverse=True))\n",
    "        #res[i['text']] = result[0].detach().numpy()\n",
    "    return list(sorted(res.items(), key=lambda item: item[1], reverse=True))[:50]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:53:08.617155832Z",
     "start_time": "2024-02-06T11:53:08.499125730Z"
    }
   },
   "id": "1aa8989a0b323fba",
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:53:08.811276676Z",
     "start_time": "2024-02-06T11:53:08.676856951Z"
    }
   },
   "id": "d2a7ed0d290055c8",
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6506it [00:05, 1146.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('اضافه کردن تنظیم onignal', 0.80495614),\n ('اضافه کردن تنظیم فعالغیرفعال برای نمایش متن های از پیش تعریف شده prefined contt',\n  0.79656935),\n ('بررسی دلیل کار نکردن تنظیم veloping mo در پنل مدیریت', 0.7896117),\n ('اضافه کردن تنظیم برای زمان پیشفرض زمان سررسید مصوبه و پیگیری', 0.7810662),\n ('طراحی صفحه تنظیم تاریخ کار', 0.777129),\n ('تنظیم آتنتیکیت سیستم', 0.7734872),\n ('تنظیم فیلد های تبولیتور ها مطابق با طرح ها', 0.77012247),\n ('افزودن تنظیم برای عمومی یا خصوصی بودن الگوها', 0.7684008),\n ('ترجمه فریز اصلاح شود از ویرایش ثبت به ذخیره', 0.76694185),\n ('اضافه شدن تنظیم گروه کاربری برای ویرایش همه قرار ملاقات ها', 0.766263),\n ('افزودن تنظیم گروه کاربری برای دیدن همه پیشنهادات proposion', 0.76174885),\n ('اضافه کردن تنظیم گروه کاربری برای ویرایش تنظیمات اکانت', 0.7593921),\n ('در فیلتر چت یک تنظیم اضافه شود که همه را نمایش دهد اما آرشیوها را نمایش ندهد',\n  0.75575864),\n ('اضافه کردن تنظیم به ماژول کاربران برای ایجاد فید هنگام تغییر تصویر',\n  0.75448704),\n ('مدیریت پروژهپشتیبانیقسمت ویرایش لیست کارها هنگام ثبت ویرایش ویرایش انجام نمیشود و حتما صفحه باید رفرش شود',\n  0.75064504),\n ('تهیه دستورالعمل سنجش کیفیت خدمات مشتری و تعیین شاخص ها', 0.7490435),\n ('اضافه کردن تنظیم برای مدت انقضای توکن در سیستم', 0.7452998),\n ('تهیه دستورالعمل سنجش کیفیت خدمات مشتری و تعیین شاخص هاhappy call',\n  0.7452065),\n ('حذف کار در صفحه ثبت الگو نیاز به رفرش دارد یعنی بعد از اینکه کاری را حذف میکنیم حتما صفحه را باید ویرایش کنیم تا اعمال شود',\n  0.7451464),\n ('بررسی شود که برای تنظیم عرض و ارتفاع لوگو باید در کنترل پنل تنظیمات لحاظ کنیم یا در خود ui قابل پیاده سازی باشد تا عکس لوگو بزرگ نشود بعد از اپلود شدن',\n  0.7440188),\n ('تغییر صفحه لاگ مشخصات تخصیص بر اساس نظرات آقای روح الامین', 0.74342465),\n ('اضافه کردن تنظیم دسترسی حذف و آپلود فایل برای نقش های کاربری پروژه',\n  0.74318796),\n ('تاریخ تعیین وضعیت انجام با تاریخ سیستم تنظیم شود و انجام دهنده نتواند تاریخ های دیگری را تنظیم کند',\n  0.7417476),\n ('بررسی پروژه برنامه ریزی و ایزو برای دمو خانم بهمنی', 0.7411602),\n ('ایجاد تولتیپ برای هماهنگ کننده در قسمت نمایش مشخصات درخواست کننده ها',\n  0.740146),\n ('تنظیم گروه کاربری برای انتقال تسک ها', 0.73997575),\n ('کار کردن برروی شل نصب جدید و بررسی شل قبلی برای بهبود شل جدید', 0.7387501),\n ('تنظیم گروه کاربری برای نمایش داشبورد', 0.7381627),\n ('منوی جلسات در پیش رو علاوه بر تاریخ امروز ساعت الان را هم لحاظ کندبهتر است تنظیم باشد',\n  0.7375402),\n ('ساخت فایل bat برای تنظیم فایل هاست مشتری', 0.73747224),\n ('یک تنظیم گروه کاربری برای دسترسی به appointmt', 0.73686826),\n ('افزودن تنظیم و فریز برای دکمه های صورتجلسات', 0.736472),\n ('صفحه مای تسک در بخش های کارهای من کارهای نظارت من همه کارهای مدیریت شامل کلیه کارها باشد و امکانات فیلتر بر اساس نام پروژه وضعیت انجام کار تاریخ ایجاد کار از تاتاریخ سرسید ازتاتاریخ انجام کارازتا وضعیت تائید کار وجود داشته_باشد',\n  0.73600394),\n ('با افزودن هماکاران آنها قابلیت تایید کردن همکاری داشته_باشند', 0.734936),\n ('موارد ترجمه نشده فریز در کل سیستم بررسی و ترجمه شوند', 0.7338087),\n ('قسمت شرح اجرای دستور در قسمت دستور های مدیریتی کار نمیکند', 0.7331884),\n ('اصلاح صفحه ثبت تشکر', 0.7324006),\n ('حضور در دفتر نشر الکترونیک و تقدیم نامه توضیحات سیستم به ریاستگواهینامه ثبت و صدور شناسنامه نرم افز',\n  0.73200804),\n ('تهیه فایل ارزیابی سیستم مدیریت جلسات همسو با سایر نرمافزارها', 0.731417),\n ('نوتیف مرورگر هر ثانیه تکرار می شود بررسی اولیه با مهران انجام شد',\n  0.7295475),\n ('تغییر و افزودن استایل های مودال های ثبت و ویرایش دستور جلسات صفحات ثبت جلسه و ویرایش جلسه لیست پیشنهادات و بازبینی استایل های کل سیستم',\n  0.7290906),\n ('اجرای فاز شناخت', 0.7287048),\n ('ایجاد تنظیم برای اینکه خود پشتیبانی بتواند اکسل را تغییر بدهد بسته به خواسته مشتری',\n  0.7286795),\n ('تغییر و افزودن استایل های مودال های پیگیری و تعیین وضعیت و افزودن پیگیری صفحات ثبت جلسه پرینت مصوبه تب الحاقیه و کلیه فایل های مودال ها و فریز های این موارد',\n  0.7265683),\n ('تنظیم های نمایش تمامی عکس و همه البوم ها در ماژول کاربران در url هم کنترل شود',\n  0.72421277),\n ('ابلاغ روش اجرایی تولید', 0.7240812),\n ('افزودن تنظیم برای تعیین فایل certificate و key برای ssl', 0.72362834),\n ('ایجاد نمایش و ویرایش مشخصات اختصاصی سازمان', 0.7235231),\n ('تهیه متن و قالب ایمیل به کاربران غیرفعال جهت یادآوری محصول', 0.7233118),\n ('صحبت با آقای مظفری در مورد مکانیزم های سازمان ما و روال کارها در واحد تولید',\n  0.72308064)]"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result('تنظیم')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T12:00:22.326197981Z",
     "start_time": "2024-02-06T12:00:16.589286592Z"
    }
   },
   "id": "a77ff2f24d8754f",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class to_ngram:\n",
    "    def __init__(self, data_set, n_gram: list):\n",
    "        super(to_ngram, self).__init__()\n",
    "        self.n_gram = n_gram\n",
    "        self.data_set = data_set\n",
    "\n",
    "    def __calculate_imbalanced_label(self):\n",
    "        job_count = self.data_set.who.value_counts()\n",
    "        job_count = job_count[job_count < 50]\n",
    "        return job_count.index\n",
    "\n",
    "    def __do_not_know(self):\n",
    "        job_count = self.__calculate_imbalanced_label()\n",
    "        output_series = pd.Series()\n",
    "        for i in job_count:\n",
    "            tasks = self.data_set[self.data_set['who'] == i]['job']\n",
    "            list_of_task = []\n",
    "            for task in tasks:\n",
    "                for num in self.n_gram:\n",
    "                    word = task.split()\n",
    "                    word = ngrams(word, num)\n",
    "                    result = [' '.join(ngram) for ngram in word]\n",
    "                    if len(result) > 0:\n",
    "                        list_of_task.append(result)\n",
    "            output_series.loc[i] = list_of_task\n",
    "        return output_series\n",
    "\n",
    "    def __sep_dataset(self):\n",
    "        output_series = self.__do_not_know()\n",
    "        #full_list=defaultdict(list)\n",
    "        final_dict = {}\n",
    "        for who, jobs in output_series.items():\n",
    "            for y in jobs:\n",
    "                for z in y:\n",
    "                    final_dict[z] = who\n",
    "        return final_dict\n",
    "\n",
    "    def __result(self):\n",
    "        final_dict = self.__sep_dataset()\n",
    "        dataframe = pd.DataFrame([final_dict]).transpose().reset_index()\n",
    "        dataframe.rename(columns={'index': \"job\", int(0): \"who\"}, inplace=True)\n",
    "        return dataframe\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.__result()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:53:14.990462420Z",
     "start_time": "2024-02-06T11:53:14.952040785Z"
    }
   },
   "id": "f42212208e0fb34e",
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset=context_mongo('all_syn')\n",
    "li=[]\n",
    "for i in dataset.find({},{'_id':False})[23:24]:\n",
    "    li.append(i['name'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:49:04.210896666Z",
     "start_time": "2024-02-06T11:49:04.095719407Z"
    }
   },
   "id": "dd20d1078d18cdf6",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class n_gram:\n",
    "    def __init__(self,data_set,ngram:list):\n",
    "        super(n_gram,self).__init__()\n",
    "        self.data_set=data_set\n",
    "        self.ngram=ngram\n",
    "        \n",
    "    def do_not_know(self):\n",
    "        list_of_task = []\n",
    "        for i in self.data_set:\n",
    "            word=i.split()\n",
    "            word=ngrams(word,2)\n",
    "            \n",
    "            result = [' '.join(ngram) for ngram in word]\n",
    "            if len(result) > 0:\n",
    "                list_of_task.append(result)\n",
    "        return list_of_task"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:49:04.679156600Z",
     "start_time": "2024-02-06T11:49:04.572484926Z"
    }
   },
   "id": "79658ea50a60f7ea",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nnn=n_gram(li,[2,3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:49:05.139720999Z",
     "start_time": "2024-02-06T11:49:05.061049600Z"
    }
   },
   "id": "a42a5924db69eef6",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['طراحی اینفوگرام', 'اینفوگرام معماری', 'معماری ایمیل', 'ایمیل مارکتینگ']\n"
     ]
    }
   ],
   "source": [
    "for i in nnn.do_not_know():\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:50:06.205211220Z",
     "start_time": "2024-02-06T11:50:06.097932931Z"
    }
   },
   "id": "bd2325f3f6de93ed",
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:49:53.343933664Z",
     "start_time": "2024-02-06T11:49:53.057120618Z"
    }
   },
   "id": "4e18085011cb4908",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1652023506.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[52], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    تغییر منوی سمت راست\u001B[0m\n\u001B[0m          ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "تغییر منوی سمت راست\n",
    "\n",
    "بیزینس ناظر کار\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:38:25.008979945Z",
     "start_time": "2024-02-06T11:38:24.938420094Z"
    }
   },
   "id": "34f86d90442d87ee",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b4007f5aaef4f952"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
