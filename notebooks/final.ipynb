{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59634ce9c3b65d9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T05:38:50.306270056Z",
     "start_time": "2024-02-17T05:38:46.574884346Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import torch\n",
    "from farsi_tools import stop_words\n",
    "from hazm import word_tokenize, Lemmatizer\n",
    "from pymongo import MongoClient\n",
    "from sentence_transformers import util\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from tqdm import tqdm\n",
    "from const.constance import *\n",
    "\n",
    "\n",
    "lemmatizer = Lemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# STOP WORD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7c77a87b83e36c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(stopword_path, encoding=\"utf8\") as f:\n",
    "    stop = f.readlines()\n",
    "# cleaning stopwords\n",
    "stop_word = [word.replace('\\n', '') for word in stop]\n",
    "stop_word = [re.sub('[\\\\u200c]', ' ', word) for word in stop_word]\n",
    "stop_word.extend(stop_words())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T05:38:50.336624521Z",
     "start_time": "2024-02-17T05:38:50.292715327Z"
    }
   },
   "id": "809d5e464de0f548",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# mongo db"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a02083f5fd62333"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def context_mongo(collection_name):\n",
    "    client = MongoClient(host=host, port=port)\n",
    "    client_my = client['nlp']\n",
    "    my_coll = client_my[collection_name]\n",
    "    return my_coll"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T05:38:50.374213191Z",
     "start_time": "2024-02-17T05:38:50.313577763Z"
    }
   },
   "id": "af4243d203e0764",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "p# ==ol"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c244294e25495c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file):\n",
    "    print(\"loading glove model\")\n",
    "    model = KeyedVectors.load_word2vec_format(glove_file, binary=False)\n",
    "    print(f\"loaded glove model , {len(model)}\")\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T05:38:50.376868952Z",
     "start_time": "2024-02-17T05:38:50.321594118Z"
    }
   },
   "id": "158789c508936a54",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading glove model\n",
      "loaded glove model , 240548\n"
     ]
    }
   ],
   "source": [
    "model = load_glove_model(glove_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T05:39:01.465503788Z",
     "start_time": "2024-02-17T05:38:50.328148861Z"
    }
   },
   "id": "585a8ae0ed3a0c63",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# spell checker"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dabb2dbbca5ad531"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=3, prefix_length=8)\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T05:39:07.391138167Z",
     "start_time": "2024-02-17T05:39:01.466320830Z"
    }
   },
   "id": "945388cf874c129c",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# word 2 vector sy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f63a1016287ab41"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "word2vec_model = KeyedVectors.load_word2vec_format(word2vec_cbow_path, binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T05:39:10.822266764Z",
     "start_time": "2024-02-17T05:39:07.391070186Z"
    }
   },
   "id": "645fa766192b1d21",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test = \"تعیین مقادیر پیش فرض در ماژول جلسات\"\n",
    "test1 = \"تعیین مقادیر پیش فرض در افزونه جلسات\"\n",
    "text = \"ویدئو انیمیشن برای همکارات بفرست\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T05:39:10.847587071Z",
     "start_time": "2024-02-17T05:39:10.823311819Z"
    }
   },
   "id": "8a6efae14b0e9174",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[('ERP', 0.8689835667610168),\n ('اتوماسیون', 0.8578999042510986),\n ('راهبری', 0.8481571078300476),\n ('ICT', 0.8443616628646851),\n ('کسب\\u200cوکار', 0.8366156220436096),\n ('زیرساختی', 0.8302525877952576),\n ('Management', 0.8295701146125793),\n ('SAP', 0.8287033438682556),\n ('خودکارسازی', 0.827669084072113),\n ('مدیریتی', 0.8246448636054993),\n ('Service', 0.8239153623580933),\n ('Security', 0.8237847089767456),\n ('مشارکتی', 0.8226858973503113),\n ('سیسکو', 0.8220700621604919),\n ('توزیع\\u200cشده', 0.8212320804595947),\n ('لجستیک', 0.8208287358283997),\n ('یکپارچه\\u200cسازی', 0.8204160928726196),\n ('PLC', 0.8197720646858215),\n ('زیرساخت', 0.8197266459465027),\n ('توسعه\\u200cای', 0.8187692761421204),\n ('زیربنایی', 0.8179969787597656),\n ('مشاوره\\u200cای', 0.8171239495277405),\n ('نرم\\u200cافزاری', 0.816767156124115),\n ('مدیریت', 0.8163818717002869),\n ('IETF', 0.8143932819366455),\n ('ATM', 0.8135349154472351),\n ('Systems', 0.8115798234939575),\n ('CRM', 0.8107935786247253),\n ('سخت\\u200cافزارها', 0.8087218403816223),\n ('سرویس\\u200cها', 0.8084495067596436),\n ('بازاریابی', 0.805817186832428),\n ('سخت\\u200cافزاری', 0.805785596370697),\n ('چندرسانه\\u200cای', 0.8044797778129578),\n ('Desk', 0.8036779165267944),\n ('IEEE', 0.8035665154457092),\n ('Cisco', 0.8027501106262207),\n ('Application', 0.8012945055961609),\n ('هماهنگ\\u200cسازی', 0.8002890944480896),\n ('GIS', 0.7999411821365356),\n ('اینترانت', 0.7999266982078552),\n ('ارائه\\u200cکننده', 0.7991438508033752),\n ('موبایلی', 0.7977425456047058),\n ('دیتا', 0.7976580858230591),\n ('CAD', 0.7973035573959351),\n ('Content', 0.7964683175086975),\n ('ستادی', 0.7954818606376648),\n ('نیازمندی\\u200cها', 0.7946001887321472),\n ('channel', 0.7936426401138306),\n ('WAP', 0.7936109900474548),\n ('سازمانی', 0.7931272983551025),\n ('CDMA', 0.7929940819740295),\n ('فناوری', 0.7928908467292786),\n ('شبکه\\u200cسازی', 0.7923075556755066),\n ('Web', 0.7905803918838501),\n ('BIM', 0.7905471324920654),\n ('Microsoft', 0.7903627753257751),\n ('GSM', 0.7894939184188843),\n ('تجاری\\u200cسازی', 0.7894811034202576),\n ('انفورماتیک', 0.789459764957428),\n ('غیرمتمرکز', 0.789394199848175),\n ('اعتبارسنجی', 0.7891281843185425),\n ('رایانش', 0.7891160845756531),\n ('ارگونومی', 0.7888116240501404),\n ('تعاملی', 0.7879002690315247),\n ('Technology', 0.7878024578094482),\n ('سخت\\u200cافزار', 0.7873664498329163),\n ('نظارتی', 0.7872801423072815),\n ('نرم\\u200cافزارها', 0.7870155572891235),\n ('PKI', 0.7867386341094971),\n ('BPR', 0.786371648311615),\n ('کارآفرینی', 0.7853167653083801),\n ('Information', 0.7850229144096375),\n ('XML', 0.7845683693885803),\n ('Dynamics', 0.7844288945198059),\n ('Server', 0.7839828133583069),\n ('management', 0.7836381793022156),\n ('Infrastructure', 0.7833767533302307),\n ('الکترونیک', 0.7830200791358948),\n ('برون\\u200cسپاری', 0.7828100323677063),\n ('پرسنلی', 0.7826759219169617),\n ('تکنولوژیکی', 0.7826036214828491),\n ('مخابراتی', 0.7824714779853821),\n ('مکاترونیک', 0.7823507189750671),\n ('Mobility', 0.7823488116264343),\n ('Software', 0.7821499705314636),\n ('سرورها', 0.7819861769676208),\n ('نیازمندیهای', 0.7817735075950623),\n ('رباتیک', 0.7817310690879822),\n ('Enterprise', 0.7816498875617981),\n ('فراهم\\u200cکننده', 0.7814593315124512),\n ('وی\\u200cپی\\u200cان', 0.7813856601715088),\n ('ارائه\\u200cدهنده', 0.7804635763168335),\n ('دسکتاپ', 0.7800571322441101),\n ('بیسیم', 0.7798100709915161),\n ('Data', 0.7797693014144897),\n ('نرم\\u200cافزار', 0.7797191143035889),\n ('Process', 0.779476523399353),\n ('Active', 0.779456377029419),\n ('تصمیم\\u200cسازی', 0.7786732912063599),\n ('Omni', 0.7784785032272339),\n ('مخابرات', 0.7784768342971802),\n ('دات\\u200cنت', 0.7779789566993713),\n ('API', 0.7778556942939758),\n ('System', 0.7778360843658447),\n ('مدل\\u200cسازی', 0.7778346538543701),\n ('BPM', 0.7775505781173706),\n ('وردپرس', 0.7774360775947571),\n ('Strategy', 0.7774356007575989),\n ('BPL', 0.7771929502487183),\n ('اینفوپس', 0.7770825624465942),\n ('کاربردپذیری', 0.7768689393997192),\n ('Desktop', 0.7768470048904419),\n ('توکار', 0.7767715454101562),\n ('فن\\u200cآوری', 0.7762490510940552),\n ('Flash', 0.7762460112571716),\n ('Group', 0.7761907577514648),\n ('SQL', 0.7760621309280396),\n ('Expert', 0.7759636640548706),\n ('B2B', 0.7749555110931396),\n ('WAN', 0.7745946645736694),\n ('حسابداری', 0.7744524478912354),\n ('Services', 0.7741822600364685),\n ('لجستیکی', 0.7739577293395996),\n ('Network', 0.7739338874816895),\n ('انبارداری', 0.7738946080207825),\n ('MEMS', 0.773688554763794),\n ('سایبر', 0.7734552621841431),\n ('شیرپوینت', 0.7732237577438354),\n ('MSC', 0.7731045484542847),\n ('تکنولوژی', 0.7729945182800293),\n ('Architecture', 0.7727365493774414),\n ('کتابشناختی', 0.7727085947990417),\n ('نوآورانه', 0.7725135087966919),\n ('ZigBee', 0.7722665071487427),\n ('HTML5', 0.7719558477401733),\n ('عرضه\\u200cکننده', 0.7718708515167236),\n ('Task', 0.7716158628463745),\n ('Advanced', 0.7714582681655884),\n ('ITIL', 0.7714330554008484),\n ('Unified', 0.7713264226913452),\n ('راهبردی', 0.7712884545326233),\n ('سازمانها', 0.7712315320968628),\n ('مسیریابی', 0.7706642150878906),\n ('دارپا', 0.7705211639404297),\n ('وایمکس', 0.770453929901123),\n ('ADSL', 0.7702056169509888),\n ('3D', 0.7699962854385376),\n ('Adobe', 0.769957423210144),\n ('الکترونیکی', 0.7699369788169861),\n ('نمایه\\u200cسازی', 0.7699354887008667),\n ('کتابداری', 0.7696921229362488),\n ('مستندسازی', 0.7696042656898499),\n ('Internet', 0.7695349454879761),\n ('استانداردها', 0.769254207611084),\n ('حسابرسی', 0.7691372632980347),\n ('انفورماتیکی', 0.7689799666404724),\n ('IDE', 0.7688878774642944),\n ('هوافضا', 0.7682805061340332),\n ('بهینه\\u200cسازی', 0.7682696580886841),\n ('LAN', 0.7682127952575684),\n ('POS', 0.7679861783981323),\n ('Mobile', 0.7679314613342285),\n ('802.11', 0.7678872346878052),\n ('اعتباربخشی', 0.7677615880966187),\n ('فراهم\\u200cآوری', 0.7675334811210632),\n ('مدلسازی', 0.7671864032745361),\n ('بالادستی', 0.7670992612838745),\n ('Control', 0.7666651010513306),\n ('ساخت\\u200cوساز', 0.7664010524749756),\n ('HP', 0.7663390040397644),\n ('پورتال', 0.7663319706916809),\n ('مجازی\\u200cسازی', 0.7662993669509888),\n ('پیشرفته', 0.7662030458450317),\n ('Professional', 0.76582932472229),\n ('User', 0.7655688524246216),\n ('زیرسیستم', 0.7655631303787231),\n ('پیام\\u200cرسانی', 0.7655616998672485),\n ('LEED', 0.7654644846916199),\n ('ارتباطات', 0.7653887867927551),\n ('مقیاس\\u200cپذیری', 0.7652251720428467),\n ('مانیتورینگ', 0.7652177810668945),\n ('Engineering', 0.7651760578155518),\n ('فرایندها', 0.7649090886116028),\n ('Interface', 0.7648916244506836),\n ('داده\\u200cکاوی', 0.764889121055603),\n ('خدماتی', 0.7648800611495972),\n ('اقتصادسنجی', 0.7648013234138489),\n ('IBM', 0.7646473050117493),\n ('CAM', 0.7643474340438843),\n ('کوربا', 0.7642810344696045),\n ('VoIP', 0.7642422914505005),\n ('رایانشی', 0.7641788721084595),\n ('توسعه\\u200cی', 0.7641765475273132),\n ('رویه\\u200cها', 0.7639375925064087),\n ('سوئیچینگ', 0.763687252998352),\n ('سرویسهای', 0.7636739015579224),\n ('مهندسی', 0.7635876536369324),\n ('پویای', 0.7634002566337585),\n ('SSH', 0.7631891369819641),\n ('متن\\u200cباز', 0.7629920244216919),\n ('ارتباطاتی', 0.7626965641975403),\n ('راه\\u200cدور', 0.7626518607139587),\n ('سازمان\\u200cها', 0.7622863054275513),\n ('ماژولار', 0.7622681856155396),\n ('حمایتی', 0.7621634006500244),\n ('EHR', 0.7619968056678772),\n ('Wireless', 0.7619550228118896),\n ('drive', 0.7618975639343262),\n ('عیب\\u200cیابی', 0.7618540525436401),\n ('اشتراک\\u200cگذاری', 0.7617988586425781),\n ('udev', 0.7617000937461853),\n ('Explorer', 0.7616720199584961),\n ('client', 0.7615221738815308),\n ('اکلیپس', 0.7615095376968384),\n ('مشترکین', 0.7614325284957886),\n ('Development', 0.7613722085952759),\n ('بی\\u200cسیم', 0.761365532875061),\n ('سامانه\\u200cها', 0.7612742781639099),\n ('server', 0.7612242698669434),\n ('مراقبتی', 0.7610864639282227),\n ('اطلاع\\u200cرسانی', 0.7609608173370361),\n ('بلادرنگ', 0.760840892791748),\n ('دیتابیس', 0.7607974410057068),\n ('بیمه\\u200cای', 0.7607123851776123),\n ('B2C', 0.7605680227279663),\n ('access', 0.760557234287262),\n ('توصیه\\u200cگر', 0.7605063915252686),\n ('QoS', 0.7603554725646973),\n ('مربوطه', 0.7601202130317688),\n ('SSL', 0.7600963115692139),\n ('GPRS', 0.7600212097167969),\n ('Policy', 0.7599908113479614),\n ('اتوکد', 0.7599841356277466),\n ('اجرائی', 0.7597103118896484),\n ('Windows', 0.7596933841705322),\n ('ذی\\u200cنفعان', 0.7595835328102112),\n ('UEFI', 0.7594912648200989),\n ('محلی\\u200cسازی', 0.7594817876815796),\n ('ASP.NET', 0.759364902973175),\n ('UMTS', 0.7593570947647095),\n ('based', 0.7592100501060486),\n ('سیاستها', 0.7591588497161865),\n ('WIPS', 0.7590646743774414),\n ('MS', 0.7589312791824341),\n ('دسترس\\u200cپذیری', 0.7588158845901489),\n ('Design', 0.758766770362854),\n ('LTE', 0.7585156559944153),\n ('زیرساخت\\u200cها', 0.7583330869674683),\n ('application', 0.7583147287368774),\n ('IRC', 0.7582883238792419),\n ('تراکنش\\u200cها', 0.7579767107963562),\n ('سیستم\\u200cها', 0.7577648758888245),\n ('موردنیاز', 0.7576055526733398),\n ('وای\\u200cمکس', 0.7571864128112793),\n ('کامپیوتری', 0.7569876909255981),\n ('پروتکلی', 0.7567237615585327),\n ('سیاستگذاری', 0.7563883066177368),\n ('DBA', 0.756310224533081),\n ('پیاده\\u200cسازی', 0.7559490203857422),\n ('برخط', 0.7558038234710693),\n ('بایوس', 0.7557673454284668),\n ('بیوتکنولوژی', 0.7556601762771606),\n ('Intel', 0.7555004358291626),\n ('Database', 0.7548789978027344),\n ('Dynamic', 0.7548285722732544),\n ('RAD', 0.7548176050186157),\n ('کاربردی', 0.7547926306724548),\n ('کاریابی', 0.754691481590271),\n ('Framework', 0.7545667886734009),\n ('ماکروسافت', 0.7545104026794434),\n ('مایمو', 0.7544365525245667),\n ('استفاده\\u200cکنندگان', 0.7542828321456909),\n ('پلتفرم', 0.7542763948440552),\n ('Virtual', 0.7540866136550903),\n ('Analysis', 0.7534340620040894),\n ('CAT', 0.7534011602401733),\n ('P2P', 0.7533367872238159),\n ('کارآمدی', 0.7533056735992432),\n ('engineering', 0.7530136108398438),\n ('پیکربندی', 0.7530028820037842),\n ('تراکنشی', 0.7528162598609924),\n ('NFC', 0.7527570128440857),\n ('متلب', 0.7527238726615906),\n ('system', 0.7526298761367798),\n ('Automation', 0.7523390054702759),\n ('داده\\u200cای', 0.7522676587104797),\n ('مارکتینگ', 0.7521650195121765),\n ('ذخیره\\u200cسازی', 0.7520866394042969),\n ('Hewlett', 0.7520535588264465),\n ('کنترلی', 0.7520455121994019),\n ('بانک\\u200cداری', 0.7519698143005371),\n ('SMP', 0.7519491910934448),\n ('Google', 0.7518665790557861),\n ('محاسباتی', 0.7517181634902954),\n ('ART', 0.7517175674438477),\n ('EnOcean', 0.7516175508499146),\n ('نیازمندی\\u200cهای', 0.7515197992324829),\n ('تحقیقاتی', 0.7512759566307068),\n ('ارپی\\u200cسی', 0.7509363889694214),\n ('Business', 0.7508786916732788)]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.most_similar_cosmul('IT',topn=300)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T05:39:11.016005309Z",
     "start_time": "2024-02-17T05:39:10.842107252Z"
    }
   },
   "id": "ed453e5641f7572d",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "518d70a70faf0c24"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def read_dataset_csv(csv_fine_path):\n",
    "    df = pd.read_csv(csv_fine_path)  # read csv file\n",
    "    data_list = df.to_dict(orient='records')  # reshape to dict\n",
    "    return data_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T05:43:14.481862323Z",
     "start_time": "2024-02-17T05:43:14.435486286Z"
    }
   },
   "id": "62644542e6b7988c",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def encode_to_db(collection_name):\n",
    "    collection_name = MongoClient(host, port)\n",
    "    client = collection_name['nlp']\n",
    "    my_collection = client['encoded_new_coll_collection']\n",
    "    main_collection = client['new_coll']\n",
    "    dict_list = [i['job'] for i in main_collection.find({}, {'job'})]\n",
    "    for i in tqdm(dict_list):\n",
    "        if my_collection.find_one({'text': i}):\n",
    "            pass\n",
    "        else:\n",
    "            my_collection.insert_one({\n",
    "                'text': i,\n",
    "                'encoded': word_embedding_method(i)\n",
    "            })\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:42:21.398059688Z",
     "start_time": "2024-02-14T13:42:21.355324788Z"
    }
   },
   "id": "3ff0af5e2a555829",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def word_embedding_method(sentence):\n",
    "    try:\n",
    "        encoded_word_list = []\n",
    "        for i in preprocess(sentence):\n",
    "            if i in word2vec_model :\n",
    "                encoded_word_list.append(word2vec_model[i])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if encoded_word_list is None:\n",
    "            return None\n",
    "        else:\n",
    "            return np.mean(encoded_word_list, axis=0).tolist()\n",
    "    except KeyError as e:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:53:45.346434710Z",
     "start_time": "2024-02-14T13:53:45.302101050Z"
    }
   },
   "id": "541ff8adaf1bb8ce",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embedding_method('محتوای شبکه اجتماعی لینکدین'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:53:45.807435265Z",
     "start_time": "2024-02-14T13:53:45.697289035Z"
    }
   },
   "id": "130b302f65edf91e",
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "# preprocess"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad6c4c7ed8a3ff76"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(raw_text):\n",
    "    words = word_tokenize(raw_text)  # split a sentence to words and return an array\n",
    "    words = [i for i in words if i not in stop_word]\n",
    "    spell_checker_list = []\n",
    "    for i in range(len(words)):  # iterate in word array for checking spell\n",
    "        if not sym_spell.lookup(words[i], Verbosity.ALL, max_edit_distance=3):  # if word not exists ignore the word\n",
    "            continue\n",
    "        else:\n",
    "            word_matched = sym_spell.lookup(words[i], Verbosity.ALL, max_edit_distance=3)\n",
    "            for i in word_matched[:1]:  # take first similar word to our incorrect word\n",
    "                spell_checker_list.append(i)\n",
    "    #lemmatize = [lemmatizer.lemmatize(wo\n",
    "    # rd) for word in words]\n",
    "\n",
    "    split_lemm_words = []\n",
    "    for i in words:\n",
    "\n",
    "        if \"#\" not in i:\n",
    "            split_lemm_words.append(i)\n",
    "        else:\n",
    "            split_lemm_words.extend(i.split(\"#\"))\n",
    "    clean_words = list(set([w for w in split_lemm_words if w not in stop_word]))  # remove some word like \"و ,با, ...\"\n",
    "\n",
    "    return clean_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:41:44.514924870Z",
     "start_time": "2024-02-14T13:41:44.460188494Z"
    }
   },
   "id": "7d3d8d7aab206f49",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# word synonyms "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c1343f6cadbc8a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_similarity_of_words(sentence1, sentence2):\n",
    "    sentence_1 = preprocess(sentence1)\n",
    "\n",
    "    sentence_word_similarity = {}\n",
    "    for i in sentence_1:\n",
    "        get_similarity = word2vec_model.most_similar_cosmul(i, topn=20)\n",
    "        lemm = [lemmatizer.lemmatize(word[0]) for word in get_similarity]\n",
    "        cleaning_words = [re.sub(r'[\\u200c]', '', word) for word in lemm]\n",
    "        sentence_word_similarity[i] = list(set(cleaning_words))\n",
    "    gf_list = {}\n",
    "    for sent in sentence2:\n",
    "        sentence_2 = preprocess(sent)\n",
    "        reformed_sentence = sentence_2.copy()\n",
    "        for i, j in sentence_word_similarity.items():\n",
    "            for x in sentence_2:\n",
    "                if x in j:\n",
    "                    reformed_sentence = [i if word == x else word for word in reformed_sentence]\n",
    "        gf_list = {**gf_list, **{sent: ' '.join(reformed_sentence)}}\n",
    "    return gf_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:41:46.587146708Z",
     "start_time": "2024-02-14T13:41:46.507834049Z"
    }
   },
   "id": "89d158463b8de6c1",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# *Similarity*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47a28b6ae373519f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def final_similarity(sentence):\n",
    "    my_collection = context_mongo('new_version_of_cleaned_dataset')\n",
    "\n",
    "    vector_1 = np.mean([word_embedding_method(sentence)], axis=0)\n",
    "    result_pass = [calculate_similarity_of_words(sentence, [i['cleaned_text'] for i in my_collection.find()][:50])]\n",
    "\n",
    "    op = {}\n",
    "    for i in result_pass:\n",
    "        for j in i.values():\n",
    "            if len(j.split(' ')) > 1:\n",
    "                op[j] = np.mean([word_embedding_method(j)], axis=0)\n",
    "            else:\n",
    "                if type(word_embedding_method(j)) == float:\n",
    "                    continue\n",
    "                else:\n",
    "                    op[j] = word_embedding_method(j)\n",
    "    result_dict = {}\n",
    "    result = util.cos_sim(vector_1, np.array([j if i else None for i, j in op.items()], dtype=float))[0]\n",
    "    top_results = torch.topk(result, k=5)\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        result_dict[list(result_pass[0].keys())[int(idx)]] = np.round(score.numpy() * 100, 2)\n",
    "    return result_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:41:49.460351943Z",
     "start_time": "2024-02-14T13:41:49.434148513Z"
    }
   },
   "id": "8070a66963c2c8a7",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mfinal_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mمحتوای شبکه اجتماعی لینکدین\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[31], line 4\u001B[0m, in \u001B[0;36mfinal_similarity\u001B[0;34m(sentence)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfinal_similarity\u001B[39m(sentence):\n\u001B[1;32m      2\u001B[0m     my_collection \u001B[38;5;241m=\u001B[39m context_mongo(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnew_version_of_cleaned_dataset\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m     vector_1 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean([\u001B[43mword_embedding_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence\u001B[49m\u001B[43m)\u001B[49m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      5\u001B[0m     result_pass \u001B[38;5;241m=\u001B[39m [calculate_similarity_of_words(sentence, [i[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcleaned_text\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m my_collection\u001B[38;5;241m.\u001B[39mfind()][:\u001B[38;5;241m50\u001B[39m])]\n\u001B[1;32m      7\u001B[0m     op \u001B[38;5;241m=\u001B[39m {}\n",
      "Cell \u001B[0;32mIn[28], line 14\u001B[0m, in \u001B[0;36mword_embedding_method\u001B[0;34m(sentence)\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 14\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoded_word_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/Sentence_similarity/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m   3461\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3462\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 3464\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_methods\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mean\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3465\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/Sentence_similarity/lib/python3.8/site-packages/numpy/core/_methods.py:165\u001B[0m, in \u001B[0;36m_mean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_mean\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 165\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m     is_float16_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    169\u001B[0m     rcount \u001B[38;5;241m=\u001B[39m _count_reduce_items(arr, axis, keepdims\u001B[38;5;241m=\u001B[39mkeepdims, where\u001B[38;5;241m=\u001B[39mwhere)\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "final_similarity(\"محتوای شبکه اجتماعی لینکدین\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:41:51.272754114Z",
     "start_time": "2024-02-14T13:41:50.004578704Z"
    }
   },
   "id": "18a6a3de720dc50c",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# Sent By Sent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0c32c70702b9b77"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_similarity_of_words(sentence1, sentence2):\n",
    "    sentence_1 = preprocess(sentence1)\n",
    "    sentence_word_similarity = {}\n",
    "    for i in sentence_1:\n",
    "        get_similarity = model.most_similar_cosmul(i, topn=20)\n",
    "        lemm = [lemmatizer.lemmatize(word[0]) for word in get_similarity]\n",
    "        cleaning_words = [re.sub(r'[\\u200c]', '', word) for word in lemm]\n",
    "        sentence_word_similarity[i] = list(set(cleaning_words))\n",
    "\n",
    "    sentence_2 = preprocess(sentence2)\n",
    "\n",
    "    reformed_sentence = sentence_2.copy()\n",
    "    for i, j in sentence_word_similarity.items():\n",
    "        for x in sentence_2:\n",
    "            if x in j:\n",
    "                reformed_sentence = [i if word == x else word for word in reformed_sentence]\n",
    "    gf_list = ' '.join(reformed_sentence)\n",
    "    return gf_list\n",
    "\n",
    "\n",
    "def single_sim(sentence1, sentence2):\n",
    "    vector_1 = np.mean([word_embedding_method(sentence1)], axis=0)\n",
    "    result_pass = calculate_similarity_of_words(sentence1, sentence2)\n",
    "\n",
    "    op = {}\n",
    "    if len(result_pass.split(' ')) > 1:\n",
    "        op[result_pass] = np.mean([word_embedding_method(result_pass)], axis=0)\n",
    "    else:\n",
    "        if type(word_embedding_method(result_pass)) == float:\n",
    "            pass\n",
    "        else:\n",
    "            op[result_pass] = word_embedding_method(result_pass)\n",
    "    result_dict = {}\n",
    "    result = util.cos_sim(vector_1, np.array([j if i else None for i, j in op.items()], dtype=float))[0]\n",
    "    return result\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:41:51.561788722Z",
     "start_time": "2024-02-14T13:41:51.527606707Z"
    }
   },
   "id": "d1299fb83cea30b3",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mمحتوای شبکه اجتماعی لینکدین\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m text1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mمحتوای شبکه اجتماعی فبسبوک\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[43msingle_sim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext1\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[33], line 22\u001B[0m, in \u001B[0;36msingle_sim\u001B[0;34m(sentence1, sentence2)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msingle_sim\u001B[39m(sentence1, sentence2):\n\u001B[0;32m---> 22\u001B[0m     vector_1 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean([\u001B[43mword_embedding_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence1\u001B[49m\u001B[43m)\u001B[49m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     23\u001B[0m     result_pass \u001B[38;5;241m=\u001B[39m calculate_similarity_of_words(sentence1, sentence2)\n\u001B[1;32m     25\u001B[0m     op \u001B[38;5;241m=\u001B[39m {}\n",
      "Cell \u001B[0;32mIn[28], line 14\u001B[0m, in \u001B[0;36mword_embedding_method\u001B[0;34m(sentence)\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 14\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoded_word_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/Sentence_similarity/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m   3461\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3462\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 3464\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_methods\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mean\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3465\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/Sentence_similarity/lib/python3.8/site-packages/numpy/core/_methods.py:165\u001B[0m, in \u001B[0;36m_mean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_mean\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 165\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m     is_float16_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    169\u001B[0m     rcount \u001B[38;5;241m=\u001B[39m _count_reduce_items(arr, axis, keepdims\u001B[38;5;241m=\u001B[39mkeepdims, where\u001B[38;5;241m=\u001B[39mwhere)\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "text = \"محتوای شبکه اجتماعی لینکدین\"\n",
    "text1 = \"محتوای شبکه اجتماعی فبسبوک\"\n",
    "single_sim(text, text1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:41:52.702106528Z",
     "start_time": "2024-02-14T13:41:52.527142663Z"
    }
   },
   "id": "c321ae545e284b37",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "# for faster calculation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6778dc354076d669"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "my_collection = context_mongo('new_version_of_cleaned_dataset')\n",
    "sentences = [i['cleaned_text'] for i in my_collection.find()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:28:31.665733567Z",
     "start_time": "2024-02-14T13:28:31.614270397Z"
    }
   },
   "id": "d72e2db756fd46ab",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_upload(sentences):\n",
    "    all_predicted_sentences = {}\n",
    "    for i in tqdm(sentences):\n",
    "        tokenized = preprocess(i)\n",
    "        if len(tokenized) > 0:\n",
    "            ref_with_sim = {}\n",
    "            for word in tokenized:\n",
    "                sim_words_array = []\n",
    "                try:\n",
    "                    get_similarity = word2vec_model.most_similar_cosmul(word, topn=7)\n",
    "                    glove_s=model.most_similar_cosmul(word,topn=5)\n",
    "                    for similarity in get_similarity:\n",
    "                        sim_words_array.append(similarity[0])\n",
    "                    for glo in glove_s:\n",
    "                        sim_words_array.append(glo[0])\n",
    "                except:\n",
    "                    pass\n",
    "                ref_with_sim = {**ref_with_sim, **{word: sim_words_array}}\n",
    "            maked_sentence = []\n",
    "            for tokenized_word in preprocess(i):\n",
    "                for l, m in ref_with_sim.items():\n",
    "                    if l == tokenized_word:\n",
    "                        for ih in m:\n",
    "                            maked_sentence.append(str(i).replace(l, ih))\n",
    "            all_predicted_sentences = {**all_predicted_sentences, **{i: maked_sentence}}\n",
    "        else:\n",
    "            continue\n",
    "    return all_predicted_sentences\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:28:31.668472503Z",
     "start_time": "2024-02-14T13:28:31.656233953Z"
    }
   },
   "id": "d32a7abeabe2ac00",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:28:31.698474350Z",
     "start_time": "2024-02-14T13:28:31.665188640Z"
    }
   },
   "id": "39d9bd0ca219d6e8",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:28:31.725328085Z",
     "start_time": "2024-02-14T13:28:31.669476873Z"
    }
   },
   "id": "6291e7229792b00e",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_syn = context_mongo('gfwerrjdgfgfdgyoh')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:28:31.758278211Z",
     "start_time": "2024-02-14T13:28:31.673979176Z"
    }
   },
   "id": "7df6cd8fd41ddd28",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:33<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, j in find_upload(sentences[:50]).items():\n",
    "    if all_syn.find_one({'name': i}):\n",
    "        pass\n",
    "    else:\n",
    "        all_syn.insert_one({\n",
    "            \"name\": i,\n",
    "            \"encoded\": j\n",
    "        })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:29:13.788883120Z",
     "start_time": "2024-02-14T13:28:40.444547576Z"
    }
   },
   "id": "52eb078cf5313381",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "syn_encoded = context_mongo('uiouiouiytiha')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:29:13.796333460Z",
     "start_time": "2024-02-14T13:29:13.791604022Z"
    }
   },
   "id": "224d964aebc3898a",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [07:53,  9.47s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(all_syn.find({}, {\"_id\": False})):\n",
    "    if syn_encoded.find_one({'text': i['name']}):\n",
    "        pass\n",
    "    else:\n",
    "        syn_encoded_list = []\n",
    "        for m in i['encoded']:\n",
    "            syn_encoded_list.append(np.mean([word_embedding_method(m)], axis=0).tolist())\n",
    "        if syn_encoded_list:\n",
    "            syn_encoded.insert_one({\n",
    "                'text': i['name'],\n",
    "                'generated_sent': i['encoded'],\n",
    "                'mean_encoded': syn_encoded_list\n",
    "\n",
    "            })\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:37:07.263624912Z",
     "start_time": "2024-02-14T13:29:13.797782963Z"
    }
   },
   "id": "af5fdcd3877d08de",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def result(ref):\n",
    "    vector_1 = np.mean([word_embedding_method(ref)], axis=0)\n",
    "    res = {}\n",
    "    for i in tqdm(syn_encoded.find({}, {\"_id\": False})):\n",
    "        result = util.cos_sim(vector_1.tolist(), [ c for c in i['mean_encoded'] if type(c) !=float ])\n",
    "        res[i['text']]=np.mean(sorted(result[0].detach().numpy(),reverse=True)[:20])\n",
    "        #res[i['text']] = result[0].detach().numpy()\n",
    "    return list(sorted(res.items(), key=lambda item: item[1], reverse=True))[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:50:25.281402989Z",
     "start_time": "2024-02-14T13:50:25.234246123Z"
    }
   },
   "id": "1aa8989a0b323fba",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:50:25.867531619Z",
     "start_time": "2024-02-14T13:50:25.808611733Z"
    }
   },
   "id": "d2a7ed0d290055c8",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 464.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('امکانات تعیین دسترسی ها و وضعیت پروژه', 0.9690629),\n ('امکانات پردازش پروژه و تخصیص پیشرفت کار', 0.7905096),\n ('امکانات فایل های پروژه', 0.7751187),\n ('امکانات برچسب کارها و پروژه ها', 0.75007397),\n ('امکانات بودجه و هزینه', 0.6937394),\n ('امکانات لیست کارها', 0.6663345),\n ('محتوای صفحات وب مدیریت پروژه', 0.65375483),\n ('تست و رفع ایرادات مدیریت کارها', 0.6363095),\n ('تامین تجهیزات اداری بیسیم دوربین مداربسته اداره کل حفاظت محیط زیست استان تهران',\n  0.607102),\n ('تکمیل لیست تجهیزات اداری', 0.5997367),\n ('امکانات گفتمان ها', 0.5925042),\n ('طراحی سایت همسو و صفحات داخلی آن', 0.5881273),\n ('امکانات تایم شیت', 0.5766343),\n ('اصلاح و تست پروفایل دانش', 0.5747388),\n ('راهنمای مدیریت پروژه', 0.56618136),\n ('محتوای صفحه هدف و قیمت گذاری ثبت نام', 0.555218),\n ('تهیه مدل رشد', 0.5368761),\n ('برنامه ریزی برای ایمیل مارکتینگ', 0.52469915),\n ('دیجیتال مارکتینگ و توسعه بازار', 0.522797),\n ('محتوای شبکه اجتماعی لینکدین', 0.5157046)]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result('امکانات تعیین دسترسی ها و وضعیت پروژه')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:50:26.345234930Z",
     "start_time": "2024-02-14T13:50:26.095637904Z"
    }
   },
   "id": "a77ff2f24d8754f",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (3758142603.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[130], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    \\from nltk import ngrams\u001B[0m\n\u001B[0m                            ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "\\from nltk import ngrams\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class to_ngram:\n",
    "    def __init__(self, data_set, n_gram: list):\n",
    "        super(to_ngram, self).__init__()\n",
    "        self.n_gram = n_gram\n",
    "        self.data_set = data_set\n",
    "\n",
    "    def __calculate_imbalanced_label(self):\n",
    "        job_count = self.data_set.who.value_counts()\n",
    "        job_count = job_count[job_count < 50]\n",
    "        return job_count.index\n",
    "\n",
    "    def __do_not_know(self):\n",
    "        job_count = self.__calculate_imbalanced_label()\n",
    "        output_series = pd.Series()\n",
    "        for i in job_count:\n",
    "            tasks = self.data_set[self.data_set['who'] == i]['job']\n",
    "            list_of_task = []\n",
    "            for task in tasks:\n",
    "                for num in self.n_gram:\n",
    "                    word = task.split()\n",
    "                    word = ngrams(word, num)\n",
    "                    result = [' '.join(ngram) for ngram in word]\n",
    "                    if len(result) > 0:\n",
    "                        list_of_task.append(result)\n",
    "            output_series.loc[i] = list_of_task\n",
    "        return output_series\n",
    "\n",
    "    def __sep_dataset(self):\n",
    "        output_series = self.__do_not_know()\n",
    "        #full_list=defaultdict(list)\n",
    "        final_dict = {}\n",
    "        for who, jobs in output_series.items():\n",
    "            for y in jobs:\n",
    "                for z in y:\n",
    "                    final_dict[z] = who\n",
    "        return final_dict\n",
    "\n",
    "    def __result(self):\n",
    "        final_dict = self.__sep_dataset()\n",
    "        dataframe = pd.DataFrame([final_dict]).transpose().reset_index()\n",
    "        dataframe.rename(columns={'index': \"job\", int(0): \"who\"}, inplace=True)\n",
    "        return dataframe\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.__result()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T10:18:24.393689517Z",
     "start_time": "2024-02-14T10:18:24.362307489Z"
    }
   },
   "id": "f42212208e0fb34e",
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset=context_mongo('all_syn')\n",
    "li=[]\n",
    "for i in dataset.find({},{'_id':False})[23:24]:\n",
    "    li.append(i['name'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:49:04.210896666Z",
     "start_time": "2024-02-06T11:49:04.095719407Z"
    }
   },
   "id": "dd20d1078d18cdf6",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class n_gram:\n",
    "    def __init__(self,data_set,ngram:list):\n",
    "        super(n_gram,self).__init__()\n",
    "        self.data_set=data_set\n",
    "        self.ngram=ngram\n",
    "        \n",
    "    def do_not_know(self):\n",
    "        list_of_task = []\n",
    "        for i in self.data_set:\n",
    "            word=i.split()\n",
    "            word=ngrams(word,2)\n",
    "            \n",
    "            result = [' '.join(ngram) for ngram in word]\n",
    "            if len(result) > 0:\n",
    "                list_of_task.append(result)\n",
    "        return list_of_task"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:49:04.679156600Z",
     "start_time": "2024-02-06T11:49:04.572484926Z"
    }
   },
   "id": "79658ea50a60f7ea",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_gram(li,[2,3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T11:49:05.139720999Z",
     "start_time": "2024-02-06T11:49:05.061049600Z"
    }
   },
   "id": "a42a5924db69eef6",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a0ed8a13ca26d561"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
